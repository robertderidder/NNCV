{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 and 2: Introduction and Data-driven Image Classification\n",
    "\n",
    "Welcome to this first hands-on tutorial! In this notebook, we’ll explore how to train a neural network for image classification using **PyTorch**, a popular deep learning framework. Our dataset of choice is the **CIFAR-10 dataset**, a well-known collection of 60,000 color images (32x32 pixels each) across 10 categories, such as airplanes, cats, and cars. Each category contains 6,000 images, providing a rich dataset for learning.\n",
    "\n",
    "For this task, we will build a **Multi-Layer Perceptron (MLP)**, a foundational type of artificial neural network. An MLP consists of:\n",
    "\n",
    "- **Input Layer**: Processes the raw image data.\n",
    "- **Hidden Layers**: Extract meaningful patterns and features.\n",
    "- **Output Layer**: Maps the learned features to one of the 10 image classes.\n",
    "\n",
    "The connections between nodes in these layers are weighted, and the network learns to adjust these weights during training to improve classification accuracy.\n",
    "\n",
    "By the end of this notebook, you’ll understand how to:\n",
    "1. Preprocess image data for neural network training.\n",
    "2. Build and train an MLP using PyTorch.\n",
    "3. Evaluate the performance of the trained model.\n",
    "\n",
    "Let’s dive in and start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries and load the CIFAR-10 dataset\n",
    "\n",
    "In this step, we’ll prepare our tools and data to kickstart the project. First, we’ll import the necessary libraries that make it possible to handle data, build and train neural networks, and visualize results effectively. \n",
    "\n",
    "Next, we’ll load the **CIFAR-10 dataset** using `torchvision`. As a quick refresher, the CIFAR-10 dataset contains 60,000 color images (32x32 pixels) evenly distributed across 10 classes (e.g., airplanes, cats, and cars). Each class has 6,000 images, providing a balanced and diverse dataset for training.\n",
    "\n",
    "To ensure optimal model performance, we’ll also **normalize** the images. Normalization scales the pixel values of the images to a similar range, typically around 0, making it easier for the model to learn and speeding up the convergence process during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    ToTensor,\n",
    "    Normalize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root='./data', \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s take a moment to **visualize some images from our dataset**. This is a crucial step to better understand the data we’ll be working with. By examining these images, we can gain insights into the patterns, textures, and challenges involved in classifying them correctly. This also helps us appreciate the complexity of the task our model will tackle as it learns to distinguish between the 10 diverse classes in CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_iterator)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# show images\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print labels\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%5s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m classes[labels[j]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)))\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(img):\n\u001b[0;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m     \u001b[38;5;66;03m# undo normalization\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mtranspose(img, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # undo normalization\n",
    "    img = img.numpy()\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "train_iterator = iter(train_dataloader)\n",
    "images, labels = next(train_iterator)\n",
    "\n",
    "# show images\n",
    "imshow(make_grid(images, nrow=10))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define a simple Multi-Layer Perceptron (MLP)\n",
    "\n",
    "Next, we’ll design a simple **Multi-Layer Perceptron (MLP)** to perform image classification on the CIFAR-10 dataset. An MLP is a foundational type of artificial neural network that uses multiple layers to learn patterns in data.\n",
    "\n",
    "An MLP consists of:\n",
    "- **Input Layer**: Receives the raw input data (in our case, (normalized) image pixels).\n",
    "- **Hidden Layers**: Learn meaningful features by transforming input data through weighted connections and activation functions.\n",
    "- **Output Layer**: Maps the learned features to specific classes (10 in this case).\n",
    "\n",
    "Each node (or neuron) in one layer is connected to every node in the next layer through a weighted connection, allowing the network to capture complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # TODO: Define your own layers\n",
    "        self.fc1 = None  # replace with your implementation (make sure the input layer is compatible with the CIFAR-10 images with a size of 32*32*3)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = None  # replace with your implementation (make sure the output layer is compatible with the number of classes (n=10) in CIFAR-10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)  # flatten the images\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = MLP()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define a loss function and optimizer  \n",
    "\n",
    "In this step, we’ll define two key components of our model training process: the **loss function** and the **optimizer**.  \n",
    "\n",
    "- The **loss function** quantifies the difference between the model's predictions and the true labels. It provides feedback that guides the model on how to improve its predictions. For our classification task, we’ll use **Cross Entropy Loss**, which is well-suited for multi-class problems like CIFAR-10.  \n",
    "\n",
    "- The **optimizer** is responsible for adjusting the model’s parameters (weights and biases) to minimize the loss function. We’ll use **Stochastic Gradient Descent (SGD)**, a widely-used optimization algorithm that updates parameters incrementally during training to improve performance.  \n",
    "\n",
    "Together, these tools will enable our model to learn effectively from the data and improve its accuracy over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your own loss function\n",
    "def my_loss_function(outputs, labels):\n",
    "    # Implement your own version of CrossEntropyLoss\n",
    "    # Hint: CrossEntropyLoss is a combination of LogSoftmax and NLLLoss\n",
    "    # You might want to use torch.log and torch.exp functions\n",
    "\n",
    "    # Calculate softmax of the outputs\n",
    "    softmax_outputs = torch.exp(outputs) / torch.sum(torch.exp(outputs), dim=1, keepdim=True)\n",
    "    # Calculate negative log likelihood\n",
    "    neg_log_likelihood = -torch.log(softmax_outputs[range(labels.shape[0]), labels])\n",
    "\n",
    "    # TODO: Complete the implementation by averaging the negative log likelihood across the batch to get the final loss\n",
    "    avg_neg_log_likelihood = None\n",
    "\n",
    "    return avg_neg_log_likelihood\n",
    "\n",
    "\n",
    "criterion = my_loss_function\n",
    "optimizer = SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the network and visualize the loss  \n",
    "\n",
    "Now, it’s time to train our neural network. **Training** involves optimizing the model’s parameters (weights and biases) to minimize the loss function, allowing the network to make better predictions over time.  \n",
    "\n",
    "The training process consists of the following key steps:  \n",
    "1. **Forward Pass**: The training data is passed through the network, and predictions are generated.  \n",
    "2. **Loss Calculation**: The difference between the model’s predictions and the true labels is measured using the loss function.  \n",
    "3. **Backward Pass**: Gradients of the loss with respect to each parameter are calculated through backpropagation, allowing the model to learn how to adjust its parameters.  \n",
    "4. **Parameter Update**: The optimizer updates the model’s parameters in the direction that reduces the loss, using the gradients calculated in the backward pass.  \n",
    "\n",
    "We’ll repeat this process for several **epochs** (complete passes through the training data). After each epoch, we’ll visualize the loss to track how well the network is learning. A decreasing loss indicates that the model is improving its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(net)\n\u001b[1;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\python\\envs\\NNCV\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\python\\envs\\NNCV\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# flatten the images\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "loss_values = []  # to store loss values\n",
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        print(net)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # add the loss to running_loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # calculate average loss for this epoch\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    print('Epoch [%d] loss: %.3f' % (epoch + 1, avg_loss))\n",
    "    loss_values.append(avg_loss)  # store the loss value\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel(\"batches\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the network on test data and visualize the results  \n",
    "\n",
    "Finally, we’ll evaluate our trained network on the test dataset to see how well it performs on data it hasn’t encountered during training. Testing involves feeding the test data through the network and observing how accurately it classifies the images.  \n",
    "\n",
    "We’ll also visualize some test images alongside the model’s predictions. This simple but powerful step helps us understand the network’s strengths and weaknesses by identifying patterns it correctly classifies and areas where it might struggle.  \n",
    "\n",
    "By observing the predictions, we can gain valuable insights into the network’s performance and how well it has learned the CIFAR-10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = iter(test_dataloader)\n",
    "images, labels = next(test_iterator)\n",
    "\n",
    "# print images\n",
    "imshow(make_grid(images, nrow=10))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(10)))\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
