{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Cityscapes, wrap_dataset_for_transforms_v2\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.v2 import (\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    Resize,\n",
    "    ToImage,\n",
    "    ToDtype,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomVerticalFlip,\n",
    ")\n",
    "\n",
    "# Mapping class IDs to train IDs\n",
    "id_to_trainid = {cls.id: cls.train_id for cls in Cityscapes.classes}\n",
    "def convert_to_train_id(label_img: torch.Tensor) -> torch.Tensor:\n",
    "    return label_img.apply_(lambda x: id_to_trainid[x])\n",
    "\n",
    "# Mapping train IDs to color\n",
    "train_id_to_color = {cls.train_id: cls.color for cls in Cityscapes.classes if cls.train_id != 255}\n",
    "train_id_to_color[255] = (0, 0, 0)  # Assign black to ignored labels\n",
    "\n",
    "def convert_train_id_to_color(prediction: torch.Tensor) -> torch.Tensor:\n",
    "    batch, _, height, width = prediction.shape\n",
    "    color_image = torch.zeros((batch, 3, height, width), dtype=torch.uint8)\n",
    "\n",
    "    for train_id, color in train_id_to_color.items():\n",
    "        mask = prediction[:, 0] == train_id\n",
    "\n",
    "        for i in range(3):\n",
    "            color_image[:, i][mask] = color[i]\n",
    "\n",
    "    return color_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23508032\n",
      "16130323\n"
     ]
    }
   ],
   "source": [
    "#Import deeplabv3 and change last layers to 19 classes instead of 21\n",
    "deeplabv3 = models.segmentation.deeplabv3_resnet50() #Use resnet50 because it is smaller than resnet101\n",
    "deeplabv3.classifier[4] = nn.Conv2d(256, 19, kernel_size=(1, 1))\n",
    "nn.init.xavier_normal_(deeplabv3.classifier[4].weight) #Initialize weights\n",
    "deeplabv3.backbone.layer4[0].conv2.dilation = (2, 2) #change  to stride 16\n",
    "deeplabv3.backbone.layer4[0].conv2.padding = (2, 2)\n",
    "deeplabv3.backbone.layer4[0].downsample[0].stride = (1, 1)  # Prevents downsampling\n",
    "\n",
    "model = deeplabv3\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "for param in deeplabv3.backbone.parameters():\n",
    "    param.requires_grad = False  # Freeze the early layers\n",
    "\n",
    "for param in deeplabv3.backbone.layer4.parameters():  # Unfreeze only the last ResNet layer\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(count_parameters(deeplabv3.backbone))\n",
    "print(count_parameters(deeplabv3.classifier))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CityscapesClass(name='unlabeled', id=0, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(0, 0, 0)),                  Ignored 255\n",
    "CityscapesClass(name='ego vehicle', id=1, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(0, 0, 0)),                 Ignored 255\n",
    "CityscapesClass(name='rectification border', id=2, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(0, 0, 0)),        Ignored 255\n",
    "CityscapesClass(name='out of roi', id=3, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(0, 0, 0)),                  Ignored 255\n",
    "CityscapesClass(name='static', id=4, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(0, 0, 0)),                      Ignored 255\n",
    "CityscapesClass(name='dynamic', id=5, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(111, 74, 0)),                  Ignored 255\n",
    "CityscapesClass(name='ground', id=6, train_id=255, category='void', category_id=0, has_instances=False, ignore_in_eval=True, color=(81, 0, 81)),                    Ignored 255\n",
    "CityscapesClass(name='road', id=7, train_id=0, category='flat', category_id=1, has_instances=False, ignore_in_eval=False, color=(128, 64, 128)),                    0\n",
    "CityscapesClass(name='sidewalk', id=8, train_id=1, category='flat', category_id=1, has_instances=False, ignore_in_eval=False, color=(244, 35, 232)),                1\n",
    "CityscapesClass(name='parking', id=9, train_id=255, category='flat', category_id=1, has_instances=False, ignore_in_eval=True, color=(250, 170, 160)),               Ignored 255\n",
    "CityscapesClass(name='rail track', id=10, train_id=255, category='flat', category_id=1, has_instances=False, ignore_in_eval=True, color=(230, 150, 140)),           Ignored 255\n",
    "CityscapesClass(name='building', id=11, train_id=2, category='construction', category_id=2, has_instances=False, ignore_in_eval=False, color=(70, 70, 70)),         2\n",
    "CityscapesClass(name='wall', id=12, train_id=3, category='construction', category_id=2, has_instances=False, ignore_in_eval=False, color=(102, 102, 156)),          3\n",
    "CityscapesClass(name='fence', id=13, train_id=4, category='construction', category_id=2, has_instances=False, ignore_in_eval=False, color=(190, 153, 153)),         4\n",
    "CityscapesClass(name='guard rail', id=14, train_id=255, category='construction', category_id=2, has_instances=False, ignore_in_eval=True, color=(180, 165, 180)),   Ignored 255\n",
    "CityscapesClass(name='bridge', id=15, train_id=255, category='construction', category_id=2, has_instances=False, ignore_in_eval=True, color=(150, 100, 100)),       Ignored 255\n",
    "CityscapesClass(name='tunnel', id=16, train_id=255, category='construction', category_id=2, has_instances=False, ignore_in_eval=True, color=(150, 120, 90)),        5\n",
    "CityscapesClass(name='pole', id=17, train_id=5, category='object', category_id=3, has_instances=False, ignore_in_eval=False, color=(153, 153, 153)),                Ignored 255\n",
    "CityscapesClass(name='polegroup', id=18, train_id=255, category='object', category_id=3, has_instances=False, ignore_in_eval=True, color=(153, 153, 153)),          Ignored 255\n",
    "CityscapesClass(name='traffic light', id=19, train_id=6, category='object', category_id=3, has_instances=False, ignore_in_eval=False, color=(250, 170, 30)),        6\n",
    "CityscapesClass(name='traffic sign', id=20, train_id=7, category='object', category_id=3, has_instances=False, ignore_in_eval=False, color=(220, 220, 0)),          7\n",
    "CityscapesClass(name='vegetation', id=21, train_id=8, category='nature', category_id=4, has_instances=False, ignore_in_eval=False, color=(107, 142, 35)),           8\n",
    "CityscapesClass(name='terrain', id=22, train_id=9, category='nature', category_id=4, has_instances=False, ignore_in_eval=False, color=(152, 251, 152)),             9\n",
    "CityscapesClass(name='sky', id=23, train_id=10, category='sky', category_id=5, has_instances=False, ignore_in_eval=False, color=(70, 130, 180)),                    10\n",
    "CityscapesClass(name='person', id=24, train_id=11, category='human', category_id=6, has_instances=True, ignore_in_eval=False, color=(220, 20, 60)),                 11\n",
    "CityscapesClass(name='rider', id=25, train_id=12, category='human', category_id=6, has_instances=True, ignore_in_eval=False, color=(255, 0, 0)),                    12\n",
    "CityscapesClass(name='car', id=26, train_id=13, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=False, color=(0, 0, 142)),                    13\n",
    "CityscapesClass(name='truck', id=27, train_id=14, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=False, color=(0, 0, 70)),                   14\n",
    "CityscapesClass(name='bus', id=28, train_id=15, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=False, color=(0, 60, 100)),                   15\n",
    "CityscapesClass(name='caravan', id=29, train_id=255, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=True, color=(0, 0, 90)),                 Ignored 255\n",
    "CityscapesClass(name='trailer', id=30, train_id=255, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=True, color=(0, 0, 110)),                Ignored 255\n",
    "CityscapesClass(name='train', id=31, train_id=16, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=False, color=(0, 80, 100)),                 16\n",
    "CityscapesClass(name='motorcycle', id=32, train_id=17, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=False, color=(0, 0, 230)),             17\n",
    "CityscapesClass(name='bicycle', id=33, train_id=18, category='vehicle', category_id=7, has_instances=True, ignore_in_eval=False, color=(119, 11, 32)),              18\n",
    "CityscapesClass(name='license plate', id=-1, train_id=-1, category='vehicle', category_id=7, has_instances=False, ignore_in_eval=True, color=(0, 0, 142))]          -1\n",
    "\n",
    "Classes: Road, sidewalk, building, wall, fence, tunnel, traffic light, traffic sign, vegetation terrain, sky, person, rider, car, truck, train, motorcycle, bicycle, license plate\n",
    "Excluded: Unlabeled, ego vehicle, rectification border, out or roi, static, dynamic, ground, parking, rail track, guard rail, bridge, pole, polegroup, caravan, trailer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for reproducability\n",
    "# If you add other sources of randomness (NumPy, Random), \n",
    "# make sure to set their seeds as well\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms to apply to the data\n",
    "class PaintingByNumbersTransform:\n",
    "      def __init__(self, id_to_color=None):\n",
    "          self.id_to_color = id_to_color  # Dictionary mapping class IDs to colors\n",
    "  \n",
    "      def random_recolor(self, label_img):\n",
    "          \"\"\"Assigns random colors to segmentation labels.\"\"\"\n",
    "          h, w = label_img.shape[1:]\n",
    "          recolored = torch.zeros((3, h, w), dtype=torch.uint8)  # Create an empty RGB image\n",
    "                  \n",
    "          unique_labels = label_img.unique()\n",
    "          color_map = {label.item(): torch.randint(0, 256, (3,), dtype=torch.uint8) for label in unique_labels}\n",
    "\n",
    "          for label, color in color_map.items():\n",
    "              mask = (label_img[0] == label)  # label_img shape is [1, h, w]\n",
    "              for c in range(3):\n",
    "                  recolored[c][mask] = color[c]\n",
    "             \n",
    "          return recolored\n",
    "  \n",
    "      def __call__(self, img, target):\n",
    "          if torch.rand(1).item() > 0.5:\n",
    "              # Load the actual ground truth color image\n",
    "              gt_color = self.random_recolor(target)\n",
    "  \n",
    "              # Blend image and color segmentation map\n",
    "              alpha = torch.rand(1).item() * 0.29 + 0.7  # Random alpha between 0.7 and 0.99\n",
    "              blended_img = alpha * img + (1 - alpha) * gt_color.float() / 255.0\n",
    "              return blended_img, target\n",
    "          \n",
    "          return img, target  # If not applying transformation, return original\n",
    "\n",
    "\n",
    "transform = Compose([\n",
    "    ToImage(),\n",
    "    Resize((256, 256)),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    PaintingByNumbersTransform(),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "# Load the dataset and make a split for training and validation\n",
    "train_dataset = Cityscapes(\n",
    "    \"data/cityscapes\", \n",
    "    split=\"train\", \n",
    "    mode=\"fine\", \n",
    "    target_type=\"semantic\", \n",
    "    transforms=transform\n",
    ")\n",
    "valid_dataset = Cityscapes(\n",
    "    \"data/cityscapes\", \n",
    "    split=\"val\", \n",
    "    mode=\"fine\", \n",
    "    target_type=\"semantic\", \n",
    "    transforms=transform\n",
    ")\n",
    "\n",
    "train_dataset = wrap_dataset_for_transforms_v2(train_dataset)\n",
    "valid_dataset = wrap_dataset_for_transforms_v2(valid_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True,\n",
    "    num_workers=10\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False,\n",
    "    num_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoloring(target):\n",
    "    recolored = torch.zeros((3, 3, 3), dtype=torch.uint8)  # Create an empty RGB image\n",
    "    unique_labels = label_img.unique()\n",
    "    color_map = {label.item(): torch.randint(0, 256, (3,), dtype=torch.uint8) for label in unique_labels}\n",
    "\n",
    "    for label, color in color_map.items():\n",
    "        mask = label_img == label  # Shape: (h, w)\n",
    "        recolored[mask] = color  # Assign the color to the masked pixels\n",
    "    return recolored\n",
    "\n",
    "label_img = torch.tensor([[1,1,1],[2,3,2],[4,4,4]])\n",
    "color_img = recoloring(label_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "# Define the model\n",
    "model = deeplabv3.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore the void class\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.classifier.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.MultiplicativeLR(optimizer,lambda epoch: 0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001/0010\n",
      "Epoch 0002/0010\n",
      "Epoch 0003/0010\n",
      "Epoch 0004/0010\n",
      "Epoch 0005/0010\n",
      "Epoch 0006/0010\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Training loop\n",
    "best_valid_loss = float('inf')\n",
    "current_best_model_path = None\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch+1:04}/{10:04}\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        labels = convert_to_train_id(labels)  # Convert class IDs to train IDs\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        labels = labels.long().squeeze(1)  # Remove channel dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)['out']\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        for i, (images, labels) in enumerate(valid_dataloader):\n",
    "            labels = convert_to_train_id(labels)  # Convert class IDs to train IDs\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            labels = labels.long().squeeze(1)  # Remove channel dimension\n",
    "\n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "            if i == 0:\n",
    "                predictions = outputs.softmax(1).argmax(1)\n",
    "\n",
    "                predictions = predictions.unsqueeze(1)\n",
    "                labels = labels.unsqueeze(1)\n",
    "\n",
    "                predictions = convert_train_id_to_color(predictions)\n",
    "                labels = convert_train_id_to_color(labels)\n",
    "\n",
    "                predictions_img = make_grid(predictions.cpu(), nrow=8)\n",
    "                labels_img = make_grid(labels.cpu(), nrow=8)\n",
    "\n",
    "                predictions_img = predictions_img.permute(1, 2, 0).numpy()\n",
    "                labels_img = labels_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "        \n",
    "        valid_loss = sum(losses) / len(losses)\n",
    "       \n",
    "        # if valid_loss < best_valid_loss:\n",
    "        #     best_valid_loss = valid_loss\n",
    "        #     if current_best_model_path:\n",
    "        #         os.remove(current_best_model_path)\n",
    "        #     current_best_model_path = os.path.join(\n",
    "        #         output_dir, \n",
    "        #         f\"best_model-epoch={epoch:04}-val_loss={valid_loss:04}.pth\"\n",
    "        #     )\n",
    "        #     torch.save(model.state_dict(), current_best_model_path)\n",
    "    \n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    os.path.join(\n",
    "        output_dir,\n",
    "        f\"final_model-epoch={epoch:04}-val_loss={valid_loss:04}.pth\"\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
